{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a7dfb05-94e2-4420-b025-d0daca0c0ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2022662a-876c-48e8-ab0b-32da64aa2540",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "679ba773-ef24-4e98-a290-8f333e45d761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "dataset = load_dataset(\"json\", data_files=\"./arxiv_dataset.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6da7c5db-3ca0-4f2f-9069-b2ec4738a502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0226a7e61af64354beec720e6b584c9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2700231 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Preprocess: Join title + abstract\n",
    "def preprocess_data(example):\n",
    "    return {\"text\": example[\"title\"] + \" \" + example[\"abstract\"]}\n",
    "\n",
    "processed_dataset = dataset[\"train\"].map(preprocess_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08575d80-0df5-4849-ae58-5a3fd2285e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f416b9bf-5ee3-4e41-a8bf-861180979659",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21b1f157dc01498283fb9487d5d13471",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kb290\\anaconda3\\envs\\py310_torch\\lib\\site-packages\\huggingface_hub-0.29.2-py3.8.egg\\huggingface_hub\\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\kb290\\.cache\\huggingface\\hub\\models--distilgpt2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0958e773c7d4449eabe9355547ea78e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/762 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1d8e599a89247dd88cd856f21b7ca54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b13b732486844e48a745effd616fdb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "609711f1eed44864ad24a494b76f638e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a2c2865b9a7463eabb4ff748ed92333",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/353M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4035e8c44aa34ef9889d64ed0fdd1154",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load tokenizer & model\n",
    "model_name = \"distilgpt2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b047f52-6d34-4909-8abf-05c8b5909d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure pad token exists\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30128861-e6ad-4b4f-baf6-8cec96104de4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e206acd35c8a4f9397be8636dd7888d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2700231 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tokenize\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"text\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=512\n",
    "    )\n",
    "tokenized_dataset = processed_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d96d119-a7a9-4534-ba15-3c174aadd05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce dataset size for demo/training\n",
    "reduced_dataset = tokenized_dataset.select(range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ffb36d7-db95-47c4-9c98-12db3b133508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-5): 6 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D(nf=2304, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=768)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=3072, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=3072)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f7039e8-3dc5-46db-a911-9595bec6bc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "793b7f1f-86ac-41f1-8c74-b83839505800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data collator\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c0d3b8b-4525-44e7-b5f8-60c645329e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import  Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cbca0442-0043-473a-aeec-cfc519d25d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./distilgpt2-arxiv\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=2,\n",
    "    save_steps=500,\n",
    "    save_total_limit=2,\n",
    "    prediction_loss_only=True,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3cc2c7ba-34f5-4a63-87a4-120eda50d004",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kb290\\AppData\\Local\\Temp\\ipykernel_17876\\3367358313.py:2: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "# Trainer setup\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=reduced_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "247e929d-04b3-4e8e-be85-60e8671fcca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='150' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [150/150 04:45, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>4.136500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3.760400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>3.616200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=150, training_loss=3.8377115885416666, metrics={'train_runtime': 287.4735, 'train_samples_per_second': 1.044, 'train_steps_per_second': 0.522, 'total_flos': 39194512588800.0, 'train_loss': 3.8377115885416666, 'epoch': 3.0})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "333e6db2-832d-4ace-823a-baf366103217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sample text\n",
    "input_text = \"Recent research in deep learning\"\n",
    "input_ids = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5390af67-de66-43d1-a9c2-ce115df9974c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    }
   ],
   "source": [
    "output = model.generate(\n",
    "    input_ids,\n",
    "    max_length=100,\n",
    "    temperature=0.7,\n",
    "    top_k=50,\n",
    "    top_p=0.95,\n",
    "    do_sample=True,\n",
    "    pad_token_id=tokenizer.eos_token_id\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "79727b07-172a-4a56-b438-e92250a1d35c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“œ Generated Text:\n",
      "\n",
      "Recent research in deep learning has shown that the neural network of neural networks is not the same as the neural network of the neural network of the open source network.\n",
      "However, some research on neural networks is being carried out on a larger scale.\n",
      "It has been shown that a network of neural networks is not the same as the neural network of the open source network of the open source network of the open source network of the open source network of the open source network of the open source network of the\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\nðŸ“œ Generated Text:\\n\")\n",
    "print(tokenizer.decode(output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "084a55e0-cc0c-466f-9712-d823a67ca880",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./distilgpt2-finetuned-arxiv\\\\tokenizer_config.json',\n",
       " './distilgpt2-finetuned-arxiv\\\\special_tokens_map.json',\n",
       " './distilgpt2-finetuned-arxiv\\\\vocab.json',\n",
       " './distilgpt2-finetuned-arxiv\\\\merges.txt',\n",
       " './distilgpt2-finetuned-arxiv\\\\added_tokens.json',\n",
       " './distilgpt2-finetuned-arxiv\\\\tokenizer.json')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"./distilgpt2-finetuned-arxiv\")\n",
    "tokenizer.save_pretrained(\"./distilgpt2-finetuned-arxiv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f1dd286-800e-4fed-8512-c22682560369",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenized_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m eval_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mtokenized_dataset\u001b[49m\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m120\u001b[39m))  \u001b[38;5;66;03m# or pick a different slice\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tokenized_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "eval_dataset = tokenized_dataset.select(range(100, 120))  # or pick a different slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "086f8e08-a906-4e96-a62e-6c59fbcb4215",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"requirements.txt\", \"w\") as f:\n",
    "    f.write(\"\"\"transformers==4.39.3\n",
    "datasets==2.18.0\n",
    "torch==2.2.2\n",
    "sacrebleu==2.4.0\n",
    "rouge-score==0.1.2\n",
    "numpy==1.26.4\n",
    "scikit-learn==1.4.1\n",
    "tqdm==4.66.2\n",
    "matplotlib==3.8.4\n",
    "pandas==2.2.2\n",
    "jupyterlab==4.1.5\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0e232c5-f968-405e-893c-a7217469352e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"README.md\", \"w\") as f:\n",
    "    f.write(\"\"\"\n",
    "    # DistilGPT2 arXiv Abstract Generator \n",
    "\n",
    "This project explores fine-tuning DistilGPT2 to generate scientific abstracts using a curated subset of the arXiv dataset.\n",
    "\n",
    "## Project Structure\n",
    "- `fine_tune.py`: Training script using Hugging Face Transformers\n",
    "- `evaluation.py`: Evaluation script with BLEU, ROUGE, and Perplexity\n",
    "- `paper/`: Contains the research paper (`.md` and `.pdf`)\n",
    "- `outputs/`: Generated abstract samples\n",
    "- `requirements.txt`: Python dependencies\n",
    "\n",
    "##  Results\n",
    "- Final Training Loss: ~3.83\n",
    "- Validation Perplexity: ~33.91\n",
    "- BLEU/ROUGE scores included in the paper\n",
    "\n",
    "##  Setup\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3586dd6d-d269-47de-b3cc-fc527d6b1db1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
